{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: Mevin Moncy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X,y = load_concrete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set? - ans random state??\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a2d2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(max_depth=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=5, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(max_depth=5, random_state=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "#------\n",
    "\n",
    "X_train_tree, X_val_tree, y_train_tree, y_val_tree = train_test_split(X, y, random_state=0)\n",
    "tree = DecisionTreeRegressor(max_depth=5, random_state=0)\n",
    "tree.fit(X_train_tree,y_train_tree)\n",
    "\n",
    "\n",
    "X_train_forest, X_val_forest, y_train_forest, y_val_forest = train_test_split(X, y, random_state=0)\n",
    "forest = RandomForestRegressor(max_depth=5, random_state=0)\n",
    "forest.fit(X_train_forest,y_train_forest)\n",
    "\n",
    "\n",
    "X_train_gbm, X_val_gbm, y_train_gbm, y_val_gbm = train_test_split(X, y, random_state=0)\n",
    "gbm = GradientBoostingRegressor(max_depth= 5, random_state=0)\n",
    "gbm.fit(X_train_gbm,y_train_gbm) #n_estimators=100, learning_rate=0.1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e1ad74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree - MSE Training score:  47.279760500220995\n",
      "Tree - Validition score:  73.44733108555468\n",
      "\n",
      "Forest - MSE Training score:  29.577454563550077\n",
      "Forest - MSE Validition score:  45.059350642815076\n",
      "\n",
      "gbm - MSE Training score:  3.3794401902757087\n",
      "gbm - MSE Validition score:  22.78322087027339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculate the average training and validation accuracy using mean squared \n",
    "# error with cross-validation.\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "tree_train_scores = cross_validate(tree, X_train_tree, y_train_tree,scoring='neg_mean_squared_error', cv=5, return_train_score=True) \n",
    "\n",
    "tree_train_scores1= tree_train_scores['train_score'].mean() *-1\n",
    "tree_train_scores2 = tree_train_scores['test_score'].mean() *-1\n",
    "\n",
    "print(\"Tree - MSE Training score: \", tree_train_scores1)\n",
    "print(\"Tree - Validition score: \", tree_train_scores2)\n",
    "print()\n",
    "\n",
    "#----\n",
    "forest_train_scores = cross_validate(forest, X_train_forest, y_train_forest,scoring='neg_mean_squared_error', cv=5, return_train_score=True) \n",
    "\n",
    "forest_train_scores1 = forest_train_scores['train_score'].mean() *-1\n",
    "forest_train_scores2 = forest_train_scores['test_score'].mean() *-1\n",
    "\n",
    "print(\"Forest - MSE Training score: \", forest_train_scores1)\n",
    "print(\"Forest - MSE Validition score: \", forest_train_scores2)\n",
    "print()\n",
    "# #-----\n",
    "gbm_train_scores = cross_validate(gbm, X_train_gbm, y_train_gbm,scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    " \n",
    "\n",
    "gbm_train_scores1 = gbm_train_scores['train_score'].mean() *-1\n",
    "gbm_train_scores2 = gbm_train_scores['test_score'].mean() *-1\n",
    "\n",
    "print(\"gbm - MSE Training score: \", gbm_train_scores1)\n",
    "print(\"gbm - MSE Validition score: \", gbm_train_scores2)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree - MSE Training score:  47.28\n",
      "Tree - Validition score:  73.447\n",
      "\n",
      "Forest - MSE Training score:  29.577\n",
      "Forest - MSE Validition score:  45.059\n",
      "\n",
      "gbm - MSE Training score:  3.379\n",
      "gbm - MSE Validition score:  22.783\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>47.28</td>\n",
       "      <td>73.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>29.577</td>\n",
       "      <td>45.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>3.379</td>\n",
       "      <td>22.783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Training Accuracy Validation Accuracy\n",
       "DT             47.28              73.447\n",
       "RF            29.577              45.059\n",
       "GB             3.379              22.783"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "#------\n",
    "\n",
    "X_train_tree, X_val_tree, y_train_tree, y_val_tree = train_test_split(X, y, random_state=0)\n",
    "tree = DecisionTreeRegressor(max_depth=5, random_state=0)\n",
    "tree.fit(X_train_tree,y_train_tree)\n",
    "\n",
    "\n",
    "X_train_forest, X_val_forest, y_train_forest, y_val_forest = train_test_split(X, y, random_state=0)\n",
    "forest = RandomForestRegressor(max_depth=5, random_state=0)\n",
    "forest.fit(X_train_forest,y_train_forest)\n",
    "\n",
    "\n",
    "X_train_gbm, X_val_gbm, y_train_gbm, y_val_gbm = train_test_split(X, y, random_state=0)\n",
    "gbm = GradientBoostingRegressor(max_depth= 5, random_state=0)\n",
    "gbm.fit(X_train_gbm,y_train_gbm) #n_estimators=100, learning_rate=0.1\n",
    "\n",
    "\n",
    "\n",
    "#-------\n",
    "#Calculate the average training and validation accuracy using mean squared \n",
    "# error with cross-validation.\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "tree_train_scores = cross_validate(tree, X_train_tree, y_train_tree,scoring='neg_mean_squared_error', cv=5, return_train_score=True) \n",
    "\n",
    "tree_train_scores1= tree_train_scores['train_score'].mean() *-1\n",
    "tree_train_scores2 = tree_train_scores['test_score'].mean() *-1\n",
    "\n",
    "tree_train_scores1 = round(tree_train_scores1, 3)\n",
    "tree_train_scores2 = round(tree_train_scores2, 3)\n",
    "\n",
    "print(\"Tree - MSE Training score: \", tree_train_scores1)\n",
    "print(\"Tree - Validition score: \", tree_train_scores2)\n",
    "print()\n",
    "\n",
    "#----\n",
    "forest_train_scores = cross_validate(forest, X_train_forest, y_train_forest,scoring='neg_mean_squared_error', cv=5, return_train_score=True) \n",
    "\n",
    "forest_train_scores1 = forest_train_scores['train_score'].mean() *-1\n",
    "forest_train_scores2 = forest_train_scores['test_score'].mean() *-1\n",
    "\n",
    "forest_train_scores1 = round(forest_train_scores1, 3)\n",
    "forest_train_scores2 = round(forest_train_scores2, 3)\n",
    "\n",
    "print(\"Forest - MSE Training score: \", forest_train_scores1)\n",
    "print(\"Forest - MSE Validition score: \", forest_train_scores2)\n",
    "print()\n",
    "# #-----\n",
    "gbm_train_scores = cross_validate(gbm, X_train_gbm, y_train_gbm,scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    " \n",
    "\n",
    "gbm_train_scores1 = gbm_train_scores['train_score'].mean() *-1\n",
    "gbm_train_scores2 = gbm_train_scores['test_score'].mean() *-1\n",
    "\n",
    "gbm_train_scores1 = round(gbm_train_scores1, 3)\n",
    "gbm_train_scores2 = round(gbm_train_scores2, 3)\n",
    "\n",
    "print(\"gbm - MSE Training score: \", gbm_train_scores1)\n",
    "print(\"gbm - MSE Validition score: \", gbm_train_scores2)\n",
    "print()\n",
    "\n",
    "\n",
    "#------------------\n",
    "results = pd.DataFrame(columns=[\"Training Accuracy\", \"Validation Accuracy\"], index=[\"DT\", \"RF\", \"GB\"])\n",
    "results.loc[\"DT\"] = [tree_train_scores1, tree_train_scores2]\n",
    "results.loc[\"RF\"] = [forest_train_scores1, forest_train_scores2]\n",
    "results.loc[\"GB\"] = [gbm_train_scores1, gbm_train_scores2]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree - R2 Training score:  0.834\n",
      "Tree - R2 Validition score:  0.739\n",
      "\n",
      "Forest - R2 Training score:  0.897\n",
      "Forest - R2 Validition score:  0.841\n",
      "\n",
      "GBM - R2 Training score:  0.988\n",
      "GBM - R2 Validition score:  0.919\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Training Accuracy Validation Accuracy\n",
       "DT             0.834               0.739\n",
       "RF             0.897               0.841\n",
       "GB             0.988               0.919"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "#Calculate the average training and validation accuracy using mean squared \n",
    "# error with cross-validation.\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "tree_train_scores = cross_validate(tree, X_train_tree, y_train_tree,scoring='r2', cv=5, return_train_score=True) \n",
    "\n",
    "tree_train_scores1= tree_train_scores['train_score'].mean() \n",
    "tree_train_scores2 = tree_train_scores['test_score'].mean() \n",
    "\n",
    "tree_train_scores1 = round(tree_train_scores1, 3)\n",
    "tree_train_scores2 = round(tree_train_scores2, 3)\n",
    "\n",
    "print(\"Tree - R2 Training score: \", tree_train_scores1)\n",
    "print(\"Tree - R2 Validition score: \", tree_train_scores2)\n",
    "print()\n",
    "\n",
    "#----\n",
    "forest_train_scores = cross_validate(forest, X_train_forest, y_train_forest,scoring='r2', cv=5, return_train_score=True) \n",
    "\n",
    "forest_train_scores1 = forest_train_scores['train_score'].mean() \n",
    "forest_train_scores2 = forest_train_scores['test_score'].mean() \n",
    "\n",
    "forest_train_scores1 = round(forest_train_scores1, 3)\n",
    "forest_train_scores2 = round(forest_train_scores2, 3)\n",
    "\n",
    "print(\"Forest - R2 Training score: \", forest_train_scores1)\n",
    "print(\"Forest - R2 Validition score: \", forest_train_scores2)\n",
    "print()\n",
    "# #-----\n",
    "gbm_train_scores = cross_validate(gbm, X_train_gbm, y_train_gbm,scoring='r2', cv=5, return_train_score=True)\n",
    " \n",
    "\n",
    "gbm_train_scores1 = gbm_train_scores['train_score'].mean() \n",
    "gbm_train_scores2 = gbm_train_scores['test_score'].mean() \n",
    "\n",
    "gbm_train_scores1 = round(gbm_train_scores1, 3)\n",
    "gbm_train_scores2 = round(gbm_train_scores2, 3)\n",
    "\n",
    "print(\"GBM - R2 Training score: \", gbm_train_scores1)\n",
    "print(\"GBM - R2 Validition score: \", gbm_train_scores2)\n",
    "print()\n",
    "\n",
    "#-----\n",
    "results = pd.DataFrame(columns=[\"Training Accuracy\", \"Validation Accuracy\"], index=[\"DT\", \"RF\", \"GB\"])\n",
    "results.loc[\"DT\"] = [tree_train_scores1, tree_train_scores2]\n",
    "results.loc[\"RF\"] = [forest_train_scores1, forest_train_scores2]\n",
    "results.loc[\"GB\"] = [gbm_train_scores1, gbm_train_scores2]\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95cf5fb",
   "metadata": {},
   "source": [
    "DT = IS high variance becuase there .1 difference, therefore overfittign can be observed\n",
    "\n",
    "RF= BETTER than DT\n",
    "\n",
    "GB = perfmored the best, but can tweak the model to have validation to be close to training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "\n",
    "Answer 1: In Assignment 2 for linear regression, the R2 training score was 0.611 and validation score was 0.623, and MSE was 111.35 for training score and 95.904 for validation score. But compared to this assignment 3's non-linear model, the training and validation accuracy was are much better for both R2 and MSE score for assignment 3 than assignment 2 linear regressgion model. From the results from assignment 3, the Gradient Boosting model was 0.988 for training score , and 0.919 for for validation score, for R2 score. And for MSE score it was 3.379 for training and 22.783 for validation score. For Decision tree, for R2 score it was 0.834 for training and 0.739 for validation, and the MSE is 47.28 for training and 73.447 for validation score. For Random forest, the R2 score was 0.897 for training and 0.841 for validation, and for MSE it was 29.577 for training score and for validation it was 45.059.\n",
    "\n",
    "Answer 2: Gradient Boosting Regressor model performed the best for both R2 and MSE. The R2 score was 0.988 for training and the validation score was 0.919, and the MSE score was 3.379 for training and 22.783 for validation score.Therefore I would select this model for this data set. These scores indicate that the model performed very well compared to the other models used. \n",
    "\n",
    "Answer 3: To increase the accuracy of the tree based models, I would tune the hyperparameters, such as Max depth. By adjusting for max depth it can increase the accuracy.\n",
    "Another suggestion is to use feature selection this will allow to extract features imptantant scores. We can use this information to select a subset of the most important features, which can lead to a more focused model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "Answer 1:\n",
    "I used the previous assignment 2 and the exmaples as reference to source my code.\n",
    "\n",
    "Answer 2:\n",
    "I started from step 1 to start the problem and worked down to complete this exercise.\n",
    "\n",
    "Answer 3:\n",
    "I used ChatGPT as the generative AI. I used the prompt \"How to import cross_validation in Machine Learning\". No, i did not modify the code becuase there is a structure to importing cross_validation, or else the import wont work.\n",
    "\n",
    "Link: https://chat.openai.com/\n",
    "\n",
    "Answer 4:\n",
    "No, I did not have any challenges. What made me successful is that, i used the previous examples and the examples showed in class to do this part of the assignment. By following those two, I was able to compelete this part.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector? - The column named Alcohol will be the target vector\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (178, 13)\n",
      "Shape of y:  (178,)\n",
      "Type of X:  <class 'pandas.core.frame.DataFrame'>\n",
      "Type of y:  <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "import os\n",
    "import requests\n",
    "\n",
    "file_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "file_name = file_url.split('/')[-1]\n",
    "\n",
    "if not os.path.isfile(file_name):\n",
    "        print('Downloading from {}'.format(file_url))\n",
    "        r = requests.get(file_url)\n",
    "        with open(file_name,'wb') as output_file:\n",
    "            output_file.write(r.content)\n",
    "            \n",
    "column_names = ['class','Alcohol', 'Malic Acid', 'Ash', 'Alcalinity of Ash', 'Magnesium', 'Total Phenols', \n",
    "                'Flavanoids', 'Nonflavanoid Phenols', 'Proanthocyanins', 'Color Intensity', \n",
    "                'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n",
    "\n",
    "\n",
    "data = pd.read_csv(file_url,na_values='?',  names=column_names)\n",
    "\n",
    "X = data.drop(columns='class')\n",
    "y = data['class']\n",
    "\n",
    "print(\"Shape of X: \",X.shape)\n",
    "print(\"Shape of y: \",y.shape)\n",
    "print(\"Type of X: \",type(X))\n",
    "print(\"Type of y: \",type(y))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class  Alcohol  Malic Acid   Ash  Alcalinity of Ash  Magnesium  \\\n",
      "0      1    14.23        1.71  2.43               15.6        127   \n",
      "1      1    13.20        1.78  2.14               11.2        100   \n",
      "2      1    13.16        2.36  2.67               18.6        101   \n",
      "3      1    14.37        1.95  2.50               16.8        113   \n",
      "4      1    13.24        2.59  2.87               21.0        118   \n",
      "\n",
      "   Total Phenols  Flavanoids  Nonflavanoid Phenols  Proanthocyanins  \\\n",
      "0           2.80        3.06                  0.28             2.29   \n",
      "1           2.65        2.76                  0.26             1.28   \n",
      "2           2.80        3.24                  0.30             2.81   \n",
      "3           3.85        3.49                  0.24             2.18   \n",
      "4           2.80        2.69                  0.39             1.82   \n",
      "\n",
      "   Color Intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
      "0             5.64  1.04                          3.92     1065  \n",
      "1             4.38  1.05                          3.40     1050  \n",
      "2             5.68  1.03                          3.17     1185  \n",
      "3             7.80  0.86                          3.45     1480  \n",
      "4             4.32  1.04                          2.93      735  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(data.isnull().sum().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0843a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#--\n",
    "X_train_svc,X_val_svc, y_train_svc, y_val_svc = train_test_split(X,y, random_state=0)\n",
    "svc = SVC()\n",
    "svc.fit(X_train_svc,y_train_svc)\n",
    "\n",
    "#--\n",
    "X_train_dtc,X_val_dtc, y_train_dtc, y_val_dtc = train_test_split(X,y, random_state=0)\n",
    "dtc = DecisionTreeClassifier(max_depth = 3)\n",
    "dtc.fit(X_train_dtc,y_train_dtc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d6c2fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc - Training Accuracy:  0.68\n",
      "svc - Validition Accuracy:  0.677\n",
      "\n",
      "Decision Tree Classifier - Training Accuracy:  0.994\n",
      "Decision Tree Classifier - Validition Accuracy:  0.872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_train_scores = cross_validate(svc, X_train_svc, y_train_svc,scoring='accuracy', cv=5, return_train_score=True)\n",
    "\n",
    "svc_train_scores1= svc_train_scores[\"train_score\"].mean()\n",
    "svc_train_scores2= svc_train_scores[\"test_score\"].mean()\n",
    "\n",
    "svc_train_scores1 = round(svc_train_scores1, 3)\n",
    "svc_train_scores2 = round(svc_train_scores2, 3)\n",
    "\n",
    "print(\"svc - Training Accuracy: \", svc_train_scores1)\n",
    "print(\"svc - Validition Accuracy: \", svc_train_scores2)\n",
    "print()\n",
    "#---\n",
    "dtc_train_scores = cross_validate(dtc, X_train_dtc, y_train_dtc,scoring='accuracy', cv=5, return_train_score=True) \n",
    "\n",
    "\n",
    "dtc_train_scores1= dtc_train_scores[\"train_score\"].mean()\n",
    "dtc_train_scores2= dtc_train_scores[\"test_score\"].mean()\n",
    "\n",
    "dtc_train_scores1 = round(dtc_train_scores1, 3)\n",
    "dtc_train_scores2 = round(dtc_train_scores2, 3)\n",
    "\n",
    "print(\"Decision Tree Classifier - Training Accuracy: \", dtc_train_scores1)\n",
    "print(\"Decision Tree Classifier - Validition Accuracy: \", dtc_train_scores2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc - Training Accuracy:  0.68\n",
      "svc - Validition Accuracy:  0.677\n",
      "\n",
      "Decision Tree Classifier - Training Accuracy:  0.994\n",
      "Decision Tree Classifier - Validition Accuracy:  0.879\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data size</th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>2314</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC</th>\n",
       "      <td>2314</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data size Training accuracy Validation accuracy\n",
       "SVC      2314              0.68               0.677\n",
       "DTC      2314             0.994               0.879"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#--\n",
    "X_train_svc,X_val_svc, y_train_svc, y_val_svc = train_test_split(X,y, random_state=0)\n",
    "svc = SVC()\n",
    "svc.fit(X_train_svc,y_train_svc)\n",
    "\n",
    "#--\n",
    "X_train_dtc,X_val_dtc, y_train_dtc, y_val_dtc = train_test_split(X,y, random_state=0)\n",
    "dtc = DecisionTreeClassifier(max_depth = 3)\n",
    "dtc.fit(X_train_dtc,y_train_dtc)\n",
    "\n",
    "#-----------------------\n",
    "svc_train_scores = cross_validate(svc, X_train_svc, y_train_svc,scoring='accuracy', cv=5, return_train_score=True)\n",
    "\n",
    "svc_train_scores1= svc_train_scores[\"train_score\"].mean()\n",
    "svc_train_scores2= svc_train_scores[\"test_score\"].mean()\n",
    "\n",
    "svc_train_scores1 = round(svc_train_scores1, 3)\n",
    "svc_train_scores2 = round(svc_train_scores2, 3)\n",
    "\n",
    "print(\"svc - Training Accuracy: \", svc_train_scores1)\n",
    "print(\"svc - Validition Accuracy: \", svc_train_scores2)\n",
    "print()\n",
    "#---\n",
    "dtc_train_scores = cross_validate(dtc, X_train_dtc, y_train_dtc,scoring='accuracy', cv=5, return_train_score=True) \n",
    "\n",
    "\n",
    "dtc_train_scores1= dtc_train_scores[\"train_score\"].mean()\n",
    "dtc_train_scores2= dtc_train_scores[\"test_score\"].mean()\n",
    "\n",
    "dtc_train_scores1 = round(dtc_train_scores1, 3)\n",
    "dtc_train_scores2 = round(dtc_train_scores2, 3)\n",
    "\n",
    "print(\"Decision Tree Classifier - Training Accuracy: \", dtc_train_scores1)\n",
    "print(\"Decision Tree Classifier - Validition Accuracy: \", dtc_train_scores2)\n",
    "print()\n",
    "\n",
    "#----------------\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Data size\",\"Training accuracy\",\"Validation accuracy\"], index = [\"SVC\", \"DTC\"])\n",
    "results.loc[\"SVC\"] = [X.size, svc_train_scores1,svc_train_scores2]\n",
    "results.loc[\"DTC\"] = [X.size, dtc_train_scores1,dtc_train_scores2]\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8516186f",
   "metadata": {},
   "source": [
    "Decision Tree Classifier gave the highest accuracy with training being 0.994 and validation being 0.894. These score much higher than SVC becuase has a training score of 0.680 and validation score of 0.677."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Decision Tree Classifier: \n",
      " [[14  2  0]\n",
      " [ 0 20  1]\n",
      " [ 0  0  8]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Implement best model\n",
    "import mglearn\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Confusion Matrix and Classification Report for Decision Tree Classifier\n",
    "y_pred_dtc = dtc.predict(X_val_dtc)\n",
    "\n",
    "# Confusion Matrix\n",
    "dtc_cm = confusion_matrix(y_val_dtc, y_pred_dtc)\n",
    "print(\"\\nConfusion Matrix for Decision Tree Classifier: \\n\",dtc_cm)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "\n",
    "sns.heatmap(dtc_cm, xticklabels=['1', '2', '3'],  yticklabels=['1', '2', '3'], square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')\n",
    "plt.title('Confusion Matrix for Decision Tree Classifier')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Decision Tree Classifier: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.88      0.93        16\n",
      "           2       0.91      0.95      0.93        21\n",
      "           3       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "# Classification Report\n",
    "dtc_report = classification_report(y_val_dtc, y_pred_dtc)\n",
    "print(\"\\nClassification Report for Decision Tree Classifier: \\n\",dtc_report)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e4ffe",
   "metadata": {},
   "source": [
    "Answer 1: For SVC model, the training accuracy was 0.68 and validation score of 0.677 for R2. And for Decision tree classifiers the R2 Scores for training was 0.994 and 0.879 for validation. From this result, we can see that Decision tree classifiers had the better results for both training and validation scores. Therefore, Decision treee classifier would be the better model.\n",
    "\n",
    "Answer 2: One of the reason why SVC did not work as well is becuase SVC are sensitive to the hyperparameters. And another reason is may due to the feature space. SVC can be influenced by feature spaces. In high dimesional spaces, models like tree-based model have an advantage.\n",
    "\n",
    "Answer 3: Three samples were incorretly classified.\n",
    "\n",
    "Answer 4: Maximizing precision is more important becuase we want to minimize false alarms and correctly classify the as much true positives as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "Answer 1: I used the class examples and previous assignment to source the code to complete this assignment.\n",
    "\n",
    "Answer 2:\n",
    "I started from step 1 to start the problem and worked down to complete this exercise.\n",
    "\n",
    "Answer 3:\n",
    "I used ChatGPT as the generative AI. I used the prompt \"How to import SVC and Decision Tree Classifier in Machine Learning \". No, i did not modify the code becuase there is a structure to importing SVC and Decision Tree Classifier, or else the import wont work.\n",
    "\n",
    "Link: https://chat.openai.com/\n",
    "\n",
    "Answer 4:\n",
    "No, I did not have any challenges. What made me successful is that, i used the previous examples shown and the examples showed in class to do this part of the assignment. By following the examples provided, I was able to compelete this part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "From my observation from part 1, for Decision tree, random forest, and gradient boosting with the max depth of 5. We see that for the decision tree the R2 score it was 0.834 for training and 0.739 for validation, and for Random forest, the R2 score was 0.897 for training and 0.841 for validation. From this we can observe that both training and validation scores improved, which makes the random forest the better model out of the two. When we compare this to the Gradient Boosting model, it was 0.988 for training score , and 0.919 for for validation score, for R2 score. This demonstrates that this model was better and got better training and validation scores compares to the other two.\n",
    "\n",
    "For part 2, we see that with the max dept of 3 for decision tree, it performed better than the SVC. Decision Tree Classifier gave the highest accuracy with training being 0.994 and validation being 0.894. These score much higher than SVC becuase has a training score of 0.680 and validation score of 0.677.\n",
    "SVC did poorly most likely due to not having any tuning for its hyperparamters.And SVC may not be the best model to represt this data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "What I liked about this assignment is that i got a chance to work with different machine learning models, and see how they work.\n",
    "I found it interesting how the confusion matrix visual worked for part 2 using the heat map and it was interesting to see how it was labeled in the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mevin\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mevin\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mevin\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mevin\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mevin\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mevin\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mevin\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC - Training Accuracy:  0.8944983248104391\n",
      "Linear SVC - Validition Accuracy:  0.8655270655270655\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mevin\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mevin\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mevin\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mevin\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mevin\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0, )\n",
    "LinearSVC_model = LinearSVC(max_iter=5000)\n",
    "LinearSVC_model.fit(X_train, y_train)\n",
    "\n",
    "LinearSVC_model_train_scores = cross_validate(LinearSVC_model, X_train, y_train,scoring='accuracy', cv=5, return_train_score=True) \n",
    "LinearSVC_model_train_scores1= LinearSVC_model_train_scores[\"train_score\"].mean()\n",
    "LinearSVC_model_train_scores2= LinearSVC_model_train_scores[\"test_score\"].mean()\n",
    "print(\"Linear SVC - Training Accuracy: \", LinearSVC_model_train_scores1)\n",
    "print(\"Linear SVC - Validition Accuracy: \", LinearSVC_model_train_scores2)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e569f1b2",
   "metadata": {},
   "source": [
    "The LinearSVC model had better results than the SVC model, becuase in the LinearSVC I got 0.894 for training and 0.8655 for validation accuracy. Therefore, using LinearSVC improved the results and it is a better fit than the SVC model. This may be due to the fact that this data be better for linear decision boundary, while the SVC has different kernal such as linear, polynomial which this dataset may not be useful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
